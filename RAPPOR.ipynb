{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RAPPOR – Server-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling scientific notation makes it a bit easier to compare numeric values with the ones logged in the R part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data files\n",
    "\n",
    "In production, the content of these files is coming from the clients. For testing, we just use files that are generated by Google's simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = \"../rappor/\"\n",
    "base += \"_tmp/python/r-gauss-small-sim_bloom_filter1_1/\"\n",
    "\n",
    "PARAMS_PATH = base + \"case_params.csv\"\n",
    "COUNTS_PATH = base + \"1/case_counts.csv\"\n",
    "MAP_PATH = base + \"case_map.csv\"\n",
    "CANDIDATES_PATH = base + \"case_unique_values.txt\" #\"case_candidates.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k, h, m, p, q, f = pd.read_csv(PARAMS_PATH).iloc[0]\n",
    "k = int(k)\n",
    "h = int(h)\n",
    "m = int(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloom filter has k=4 bits and uses h=2 hash functions\n",
      "There are m=32 cohorts\n",
      "There is a f=0.00 probability that bits in the Bloom filter are randomly changed\n",
      "p=0.50, q=0.75\n"
     ]
    }
   ],
   "source": [
    "print \"Bloom filter has k=%d bits and uses h=%d hash functions\" % (k, h)\n",
    "print \"There are m=%d cohorts\" % m\n",
    "print \"There is a f=%.2f probability that bits in the Bloom filter are randomly changed\" % f\n",
    "print \"p=%.2f, q=%.2f\" % (p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts\n",
    "\n",
    "Each row contains information about one cohort. The very first value in a row specifies the total number of reports in that cohort. The other values specify how often the respective bit was set in the sent Bloom Filter. Because some bits were randomly changed, the first value can be smaller or greater than the sum of the other values in that row.\n",
    "\n",
    "In the real server implementation, we will need a little bit of additional logic for calculating these sums. Here, we just use what Google's implementation already provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31250</td>\n",
       "      <td>18141</td>\n",
       "      <td>19440</td>\n",
       "      <td>18535</td>\n",
       "      <td>19540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31250</td>\n",
       "      <td>18492</td>\n",
       "      <td>19162</td>\n",
       "      <td>19051</td>\n",
       "      <td>18492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31250</td>\n",
       "      <td>18769</td>\n",
       "      <td>18670</td>\n",
       "      <td>19149</td>\n",
       "      <td>19340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31250</td>\n",
       "      <td>17985</td>\n",
       "      <td>19548</td>\n",
       "      <td>18788</td>\n",
       "      <td>19165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31250</td>\n",
       "      <td>18793</td>\n",
       "      <td>19899</td>\n",
       "      <td>19237</td>\n",
       "      <td>18827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4\n",
       "0  31250  18141  19440  18535  19540\n",
       "1  31250  18492  19162  19051  18492\n",
       "2  31250  18769  18670  19149  19340\n",
       "3  31250  17985  19548  18788  19165\n",
       "4  31250  18793  19899  19237  18827"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = DataFrame.from_csv(COUNTS_PATH, header=None, index_col=None)\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Exclude cohorts with $0$ reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### maps\n",
    "\n",
    "One row for every candidate string. The leftmost value in a row shows the respective string, the other values (number of cohorts * number of hash functions) show the hashed values of that string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>123</td>\n",
       "      <td>121</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>120</td>\n",
       "      <td>117</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>128</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>120</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>120</td>\n",
       "      <td>118</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2   3   4   5   6   7   8   9   10 ...    55   56   57   58   59   60  \\\n",
       "0                                          ...                                  \n",
       "v1   2   4   6   7  12   9  15  15  20  17 ...   112  109  114  115  119  120   \n",
       "v2   3   4   8   7   9  10  16  16  20  18 ...   110  110  113  114  120  117   \n",
       "v3   2   1   6   5  10  12  16  16  19  19 ...   110  109  113  115  120  119   \n",
       "v4   2   1   8   6  10  11  14  14  20  19 ...   112  110  114  113  120  117   \n",
       "v5   1   3   5   7  12  11  16  13  19  19 ...   112  111  116  114  120  118   \n",
       "\n",
       "     61   62   63   64  \n",
       "0                       \n",
       "v1  123  121  127  126  \n",
       "v2  122  122  128  126  \n",
       "v3  122  123  128  127  \n",
       "v4  123  123  128  127  \n",
       "v5  121  122  126  127  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps = DataFrame.from_csv(MAP_PATH, header=None)\n",
    "maps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### candidates\n",
    "\n",
    "Here, the candidates are simply the values that were also used by the client-side code. Generally, we would like to use a superset of these values, e.g. the most popular websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_candidates():\n",
    "    with open(CANDIDATES_PATH) as f:\n",
    "        lines = f.readlines()\n",
    "        return [candidate.strip() for candidate in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = get_candidates()\n",
    "M = len(candidates)\n",
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data to separate signal and noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high-level task of the server-side is to find out which candidate strings were really used by the clients. We will use statistical techniques for doing this, namely linear regression to find out which candidate strings probably influenced the final result.\n",
    "\n",
    "Another way to think about this: In Machine Learning and statistics we are often concerned with separating signal from noise. Here, the signal is given by the hashed values of candidate strings. The noise is added on purpose by clients in order to maintain privacy. On the server-side, we then try to use statistical techniques to remove the noise from the aggregated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target values $y$: Estimating true counts of the original Bloom filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we do some basic preprocessing to be able to use the same variables that are also being used by the RAPPOR paper. This makes it a bit easier to implement the math formulas given in the paper.\n",
    "\n",
    "$N$ is a vector containing the number of reports from the individual cohorts. $c$ is a matrix\n",
    "where $c_{ij}$ tells us how often bit $j$ was set in cohort $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = counts[0].as_matrix()\n",
    "c = counts.drop([0], axis=1).as_matrix().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target values $y$ will contain estimates of how often the individual bits were really set in the original bloom filter.\n",
    "\n",
    "$$\n",
    "t_{ij} = \\frac{c_{ij} - (p + 0.5fq - 0.5fp) N_j}{(1 - f) (q - p)}\n",
    "$$\n",
    "\n",
    "$y$ is then simply a long vector that the rows of $t$ flattened. `estimate_bloom_counts` calculates $y$ in a vectorized way.\n",
    "\n",
    "**TODO**: Motivate this formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_bloom_count(c, N):\n",
    "    Y = c - ((p + 0.5 * f * q - 0.5 * f * p) * N)\n",
    "    Y /= ((1 - f) * (q - p))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = estimate_bloom_count(c, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "print Y.shape\n",
    "assert(Y.shape == (k, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not mentioned in the paper, but actually $Y$ is then also divided by $N$ to get frequencies instead of counts. We also reshape the matrix to one long vector, and call this $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (Y / N).T.reshape(k * m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design matrix $X$: \n",
    "\n",
    "$X$ will have dimensions $km \\times M$ where\n",
    "- $k$ is the number of bits in the Bloom filter\n",
    "- $m$ is the number of cohorts\n",
    "- $M$ is the number of candidate strings\n",
    "\n",
    "Each candidate string corresponds to one feature. Each feature has $h * m$ values set to $1$, all others are $0$. This makes $X$ a sparse matrix.\n",
    "\n",
    "Each data point corresponds to one bit in a cohort. A cell is set to $1$ if the respective bit in the respective cohort is set using the respective hashed candidate string.\n",
    "\n",
    "---\n",
    "\n",
    "To get the bits set in a Bloom filter, we import a function from Google's repo. This is important because we need to make sure to use the same hash function in client and server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from client.rappor import get_bloom_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives us the bits that are set when the candidate string is hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bloom_bits(\"test\", 4, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can finally create $X$ by creating the matrices of the individual cohorts, and then stacking them vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = []\n",
    "\n",
    "for cohort in range(m):\n",
    "    rows = []\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        bits = np.zeros(k)\n",
    "        bits_set = get_bloom_bits(candidate, cohort, h, k)\n",
    "        bits[bits_set] = 1\n",
    "        rows.append(bits)\n",
    "        \n",
    "    for row in np.array(rows).T:\n",
    "        matrix.append(row)\n",
    "\n",
    "X = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "assert(X.shape == (k * m, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give some intuition on what we're doing here: The design matrix $X$ contains information about what bits would be set by which candidates and by using the estimated counts of the individual bits, we try to infer which candidate strings really appeared.\n",
    "\n",
    "**TODO**: Why statistical techniques? On a high-level view, removing the noise makes sense, but this also seems a bit like a combinatorical problem where you try to find candidates that cover all set bits\n",
    "\n",
    "**TODO**: Why do we use the estimated results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso: Eliminating some candidates\n",
    "\n",
    "In the RAPPOR paper, Google says they fit a Lasso model and only continue working with candidate strings that have non-zero coefficients. This acts as a preliminary filter to make the next model simpler.\n",
    "\n",
    "**TODO**: Understand how exactly this helps\n",
    "\n",
    "However, actually, Google only performs this Lasso regression if the number of candidates $M$ is larger than $0.8 * m * k$, as this means the system is close to being underdetermined.\n",
    "\n",
    "**TODO**: Understand why this exact check exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 102.4 | Lasso should be performed: False\n"
     ]
    }
   ],
   "source": [
    "cut_off = 0.8 * m * k\n",
    "perform_lasso = M > cut_off\n",
    "\n",
    "print M, cut_off, \"| Lasso should be performed:\", perform_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Lasso()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0., -0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
       "        0.,  0., -0., -0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
       "       -0.,  0.,  0., -0.,  0.,  0., -0., -0.,  0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_candidates = np.where(clf.coef_ > 0)[0]\n",
    "good_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[candidates[i] for i in good_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating standard deviations\n",
    "\n",
    "Because the estimated $y$ values are just expected values, it's useful to also take spread into account. We do this by calculating the standard deviations of our estimates.\n",
    "\n",
    "**TODO**: Understand how to arrive at this formula\n",
    "\n",
    "The formulas for this are not given in the paper, so the code below is directly adapted from the R code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _std_row(row, p01, p11, p2):\n",
    "    N = row[0]\n",
    "    v = row[1:]\n",
    "    \n",
    "    p_hats = (v - p01 * N) / (N * p2) # expectation of a true 1\n",
    "    p_hats = np.maximum(0, np.minimum(1, p_hats))\n",
    "    \n",
    "    r = p_hats * p11 + (1 - p_hats) * p01\n",
    "        \n",
    "    return N * r * (1 - r) / p2**2\n",
    "    \n",
    "def calculate_variances(counts):\n",
    "    p01 = p * (1 - f / 2) + q * f / 2\n",
    "    p11 = q * (1 - f / 2) + p * f / 2\n",
    "    p2 = p11 - p01\n",
    "    \n",
    "    N = counts[0].as_matrix()\n",
    "    \n",
    "    return (np.sqrt(counts.apply(lambda row: _std_row(row, p01, p11, p2), axis=1).as_matrix().T) / N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stds = calculate_variances(counts).reshape((k * m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we will use the standard deviations to resample the estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the data matrix and target values\n",
    "\n",
    "I'm not entirely sure why this is needed, and it's not mentioned in the paper, but Google also normalizes $X$ and $y$ to new variables $A, b$.\n",
    "\n",
    "**TODO**: Understand why exactly this is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_normalization(stds):\n",
    "    w = 1 / stds\n",
    "    w_median = np.median(w[np.isfinite(w)])\n",
    "\n",
    "    if not np.isfinite(w_median):\n",
    "        w_median = 1\n",
    "\n",
    "    w = np.minimum(w, 2 * w_median)\n",
    "    w = w / w.mean()\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(X, y, stds):\n",
    "    w = calculate_normalization(stds)\n",
    "    \n",
    "    A = np.diag(w).dot(X)\n",
    "    b = y * w\n",
    "    \n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = normalize(X, y, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Linear Regression\n",
    "\n",
    "In the paper, Google says they perform a \"regular least-squares regression using the selected variables\" but this is not true. The linear regression [involves additional constraints](https://github.com/google/rappor/blob/master/analysis/R/alternative.R#L22-26) (that are not described in the paper), and the input variables are also changed a bit, as we saw before.\n",
    "\n",
    "The coefficients $x$ must follow three constraints:\n",
    "\n",
    "- $x$ must be nonnegative\n",
    "- $x$ summed up to a value smaller or equal to $1$\n",
    "- The individual predictions using $x$ must not exceed the estimates by 3 standard deviations\n",
    "\n",
    "**TODO**: Understand the motivation behind these constraints\n",
    "\n",
    "The first constraint is pretty basic and can be enforced by a simple bound. The second constraint is automatically enforced by most implementations, and is also easy to enforce manually for linear models after fitting.\n",
    "\n",
    "The third constraint however makes things a bit more difficult. In general, sklearn and SciPy cannot deal with this automatically. Because of this, we have to fallback to a more low-level optimizer here that allows us to encode arbitrary constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, nnls\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third constraint, we introduce a new variable $yy$ that gives a limit for how much predicted values may differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy = np.minimum(1, np.maximum(y + 3 * stds, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the generality of our optimizer, it's important to choose a good first guess $x_0$. We generate this guess by quickly training a model using the first two constraints, but without the third. This turns out to be the critical change that allows us to get the same results as the optimization library used in R by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0, _ = nnls(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is simply least squares, i.e. we want to minimize $||Ax - b||_2^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    return norm(A.dot(x) - b, ord=2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we encode the third constraint, and run the minimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_deviation_constraint = {\n",
    "    \"type\": \"ineq\",\n",
    "    \"fun\": lambda x: max(X.dot(x) - yy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/scipy/optimize/_minimize.py:397: RuntimeWarning: Method TNC cannot handle constraints.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "x = minimize(cost,\n",
    "         x0=x0,\n",
    "         method=\"TNC\",\n",
    "         constraints=standard_deviation_constraint,\n",
    "         bounds=zip(np.zeros(M), np.ones(M))\n",
    "        ).x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends a bit on the dataset, but usually we get the exact same results as Google's RAPPOR here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00182652,  0.00012597,  0.00424327,  0.00158191,\n",
       "        0.        ,  0.        ,  0.        ,  0.00972536,  0.        ,\n",
       "        0.        ,  0.0049677 ,  0.00074506,  0.00263669,  0.00111928,\n",
       "        0.00012783,  0.00300057,  0.00013777,  0.01000537,  0.00707541,\n",
       "        0.01147606,  0.0083258 ,  0.01341316,  0.00789701,  0.00355234,\n",
       "        0.00697167,  0.00975315,  0.01727338,  0.01124086,  0.01484703,\n",
       "        0.01612965,  0.01190803,  0.0132142 ,  0.01554626,  0.01074183,\n",
       "        0.01487565,  0.01876687,  0.02007674,  0.01784912,  0.02188738,\n",
       "        0.02326081,  0.02326737,  0.02325578,  0.02368823,  0.02070788,\n",
       "        0.01840034,  0.02729136,  0.015493  ,  0.02097782,  0.02094391,\n",
       "        0.02189653,  0.02035882,  0.02031533,  0.02121134,  0.02329346,\n",
       "        0.02112202,  0.02205307,  0.02972841,  0.02478986,  0.01782075,\n",
       "        0.01936563,  0.01602125,  0.01628776,  0.0200774 ,  0.02004624,\n",
       "        0.01567713,  0.01872445,  0.01324706,  0.01072458,  0.01076157,\n",
       "        0.00745594,  0.00547923,  0.01464502,  0.00104144,  0.00536232,\n",
       "        0.00403479,  0.00499005,  0.00152745,  0.00696737,  0.        ,\n",
       "        0.00253945,  0.00160642,  0.00413785,  0.00889655,  0.0093416 ,\n",
       "        0.00253416,  0.        ,  0.        ,  0.        ,  0.00028966,\n",
       "        0.        ,  0.        ,  0.        ,  0.00024007,  0.00078204,\n",
       "        0.        ,  0.00341455,  0.        ,  0.        ,  0.00358686])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00182652,  0.00012597,  0.00424327,  0.00158191,\n",
       "        0.        ,  0.        ,  0.        ,  0.00972536,  0.        ,\n",
       "        0.        ,  0.0049677 ,  0.00074506,  0.00263669,  0.00111928,\n",
       "        0.00012783,  0.00300057,  0.00013777,  0.01000537,  0.00707541,\n",
       "        0.01147606,  0.0083258 ,  0.01341316,  0.00789701,  0.00355234,\n",
       "        0.00697167,  0.00975315,  0.01727338,  0.01124086,  0.01484703,\n",
       "        0.01612965,  0.01190803,  0.0132142 ,  0.01554626,  0.01074183,\n",
       "        0.01487565,  0.01876687,  0.02007674,  0.01784912,  0.02188738,\n",
       "        0.02326081,  0.02326737,  0.02325578,  0.02368823,  0.02070788,\n",
       "        0.01840034,  0.02729136,  0.015493  ,  0.02097782,  0.02094391,\n",
       "        0.02189653,  0.02035882,  0.02031533,  0.02121134,  0.02329346,\n",
       "        0.02112202,  0.02205307,  0.02972841,  0.02478986,  0.01782075,\n",
       "        0.01936563,  0.01602125,  0.01628776,  0.0200774 ,  0.02004624,\n",
       "        0.01567713,  0.01872445,  0.01324706,  0.01072458,  0.01076157,\n",
       "        0.00745594,  0.00547923,  0.01464502,  0.00104144,  0.00536232,\n",
       "        0.00403479,  0.00499005,  0.00152745,  0.00696737,  0.        ,\n",
       "        0.00253945,  0.00160642,  0.00413785,  0.00889655,  0.0093416 ,\n",
       "        0.00253416,  0.        ,  0.        ,  0.        ,  0.00028966,\n",
       "        0.        ,  0.        ,  0.        ,  0.00024007,  0.00078204,\n",
       "        0.        ,  0.00341455,  0.        ,  0.        ,  0.00358686])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=False)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y, stds):\n",
    "    A, b = normalize(X, y, stds)\n",
    "    yy = np.minimum(1, np.maximum(y + 3 * stds, 0.01))\n",
    "    \n",
    "    x0, _ = nnls(A, b)\n",
    "    x = minimize(cost,\n",
    "         x0=x0,\n",
    "         method=\"TNC\",\n",
    "         constraints=standard_deviation_constraint,\n",
    "         bounds=zip(np.zeros(M), np.ones(M))\n",
    "        ).x\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00182652,  0.00012597,  0.00424327,  0.00158191,\n",
       "        0.        ,  0.        ,  0.        ,  0.00972536,  0.        ,\n",
       "        0.        ,  0.0049677 ,  0.00074506,  0.00263669,  0.00111928,\n",
       "        0.00012783,  0.00300057,  0.00013777,  0.01000537,  0.00707541,\n",
       "        0.01147606,  0.0083258 ,  0.01341316,  0.00789701,  0.00355234,\n",
       "        0.00697167,  0.00975315,  0.01727338,  0.01124086,  0.01484703,\n",
       "        0.01612965,  0.01190803,  0.0132142 ,  0.01554626,  0.01074183,\n",
       "        0.01487565,  0.01876687,  0.02007674,  0.01784912,  0.02188738,\n",
       "        0.02326081,  0.02326737,  0.02325578,  0.02368823,  0.02070788,\n",
       "        0.01840034,  0.02729136,  0.015493  ,  0.02097782,  0.02094391,\n",
       "        0.02189653,  0.02035882,  0.02031533,  0.02121134,  0.02329346,\n",
       "        0.02112202,  0.02205307,  0.02972841,  0.02478986,  0.01782075,\n",
       "        0.01936563,  0.01602125,  0.01628776,  0.0200774 ,  0.02004624,\n",
       "        0.01567713,  0.01872445,  0.01324706,  0.01072458,  0.01076157,\n",
       "        0.00745594,  0.00547923,  0.01464502,  0.00104144,  0.00536232,\n",
       "        0.00403479,  0.00499005,  0.00152745,  0.00696737,  0.        ,\n",
       "        0.00253945,  0.00160642,  0.00413785,  0.00889655,  0.0093416 ,\n",
       "        0.00253416,  0.        ,  0.        ,  0.        ,  0.00028966,\n",
       "        0.        ,  0.        ,  0.        ,  0.00024007,  0.00078204,\n",
       "        0.        ,  0.00341455,  0.        ,  0.        ,  0.00358686])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(X, y, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "A popular way to get more data is resampling. Here, we use the standard deviations to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample(y, stds):\n",
    "    deviation = np.array([normal(0, std) for std in stds])\n",
    "    y += deviation\n",
    "    \n",
    "    stds = np.sqrt(stds)\n",
    "    \n",
    "    return y, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = []\n",
    "\n",
    "for i in range(5):\n",
    "    if i > 0:\n",
    "        y_resampled, stds_resampled = resample(y, stds)\n",
    "    else:\n",
    "        y_resampled, stds_resampled = y, stds\n",
    "        \n",
    "    coefs.append(fit(X, y_resampled, stds_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.00000000e+00,   1.70933534e-03,   3.74906109e-06,\n",
       "          4.29501743e-03,   1.73843614e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.58005658e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.09126606e-03,\n",
       "          5.77950980e-04,   2.64463079e-03,   1.01352657e-03,\n",
       "          8.63807391e-05,   3.03610763e-03,   0.00000000e+00,\n",
       "          9.78693776e-03,   6.88427641e-03,   1.14197607e-02,\n",
       "          8.15443339e-03,   1.36308376e-02,   7.64156313e-03,\n",
       "          3.40476071e-03,   6.91822261e-03,   9.81677476e-03,\n",
       "          1.73191792e-02,   1.14651887e-02,   1.48792707e-02,\n",
       "          1.62943244e-02,   1.18360884e-02,   1.33135127e-02,\n",
       "          1.56252280e-02,   1.07126563e-02,   1.46330569e-02,\n",
       "          1.89323380e-02,   2.01149103e-02,   1.80911209e-02,\n",
       "          2.18048915e-02,   2.34755046e-02,   2.33809697e-02,\n",
       "          2.34450964e-02,   2.36142097e-02,   2.07317091e-02,\n",
       "          1.82266311e-02,   2.74309187e-02,   1.54997230e-02,\n",
       "          2.10941102e-02,   2.10272296e-02,   2.18952317e-02,\n",
       "          2.03429348e-02,   2.04908849e-02,   2.13122391e-02,\n",
       "          2.31817595e-02,   2.09010236e-02,   2.19934373e-02,\n",
       "          2.98166218e-02,   2.48478960e-02,   1.79509196e-02,\n",
       "          1.95538099e-02,   1.60433402e-02,   1.60815334e-02,\n",
       "          2.01844443e-02,   2.00782317e-02,   1.57805250e-02,\n",
       "          1.87197843e-02,   1.31755939e-02,   1.07854063e-02,\n",
       "          1.08091282e-02,   7.61822752e-03,   5.48892321e-03,\n",
       "          1.44450300e-02,   9.24008939e-04,   5.47471438e-03,\n",
       "          4.04069509e-03,   5.19176905e-03,   1.43621976e-03,\n",
       "          7.30566991e-03,   0.00000000e+00,   2.36170937e-03,\n",
       "          1.61823593e-03,   4.05892191e-03,   8.82094651e-03,\n",
       "          9.24484755e-03,   2.45692720e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.53505158e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.07297974e-04,   6.56577524e-04,   0.00000000e+00,\n",
       "          3.55290309e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.31061029e-03]),\n",
       " array([  0.00000000e+00,   1.98037775e-03,   1.76544469e-04,\n",
       "          4.26342111e-03,   1.62345476e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.83097843e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.96827934e-03,\n",
       "          6.28382665e-04,   2.78434629e-03,   1.07912675e-03,\n",
       "          5.56441464e-05,   2.93315479e-03,   1.18888658e-04,\n",
       "          1.01451003e-02,   7.07595368e-03,   1.16559040e-02,\n",
       "          8.44977121e-03,   1.34388405e-02,   7.95935539e-03,\n",
       "          3.66871510e-03,   6.82957097e-03,   9.89729924e-03,\n",
       "          1.74189621e-02,   1.11184830e-02,   1.47566128e-02,\n",
       "          1.59817866e-02,   1.19067116e-02,   1.31079837e-02,\n",
       "          1.55562956e-02,   1.06312673e-02,   1.50040121e-02,\n",
       "          1.87496656e-02,   2.00744066e-02,   1.78187433e-02,\n",
       "          2.22192967e-02,   2.30728999e-02,   2.32142817e-02,\n",
       "          2.32161052e-02,   2.38405060e-02,   2.08191469e-02,\n",
       "          1.85777004e-02,   2.72618926e-02,   1.55688897e-02,\n",
       "          2.09386799e-02,   2.08364998e-02,   2.17656944e-02,\n",
       "          2.03136345e-02,   2.01212787e-02,   2.11879318e-02,\n",
       "          2.32201358e-02,   2.10627223e-02,   2.20876021e-02,\n",
       "          2.96847338e-02,   2.46912763e-02,   1.75672165e-02,\n",
       "          1.93392990e-02,   1.61117694e-02,   1.64259703e-02,\n",
       "          2.01625076e-02,   2.01506146e-02,   1.56129241e-02,\n",
       "          1.85691169e-02,   1.33149349e-02,   1.06025991e-02,\n",
       "          1.08079359e-02,   7.38420121e-03,   5.58000775e-03,\n",
       "          1.47846288e-02,   9.47178922e-04,   5.24070139e-03,\n",
       "          4.02307779e-03,   4.88138733e-03,   1.45756398e-03,\n",
       "          6.87248955e-03,   0.00000000e+00,   2.65884443e-03,\n",
       "          1.72279486e-03,   4.22431556e-03,   8.95631315e-03,\n",
       "          9.38710316e-03,   2.53631180e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.28149079e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.03819693e-04,   6.99529181e-04,   0.00000000e+00,\n",
       "          3.34485416e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.69435028e-03]),\n",
       " array([  0.00000000e+00,   1.85164064e-03,   3.20226412e-04,\n",
       "          4.22499418e-03,   1.50415803e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.77256699e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.88076201e-03,\n",
       "          8.52099037e-04,   2.66253880e-03,   1.17570509e-03,\n",
       "          5.37764675e-05,   2.84034238e-03,   6.43875576e-05,\n",
       "          1.00991264e-02,   7.18514066e-03,   1.16437387e-02,\n",
       "          8.51871724e-03,   1.32748154e-02,   7.94077382e-03,\n",
       "          3.66348851e-03,   6.82410415e-03,   9.84327793e-03,\n",
       "          1.72900480e-02,   1.12021724e-02,   1.48214808e-02,\n",
       "          1.60496026e-02,   1.19230431e-02,   1.31358320e-02,\n",
       "          1.55038129e-02,   1.06256315e-02,   1.48598445e-02,\n",
       "          1.88068962e-02,   2.00142076e-02,   1.77959352e-02,\n",
       "          2.20549846e-02,   2.31159208e-02,   2.32205739e-02,\n",
       "          2.31994059e-02,   2.36546515e-02,   2.08487630e-02,\n",
       "          1.86236899e-02,   2.73678442e-02,   1.54467538e-02,\n",
       "          2.09260390e-02,   2.08852244e-02,   2.19565553e-02,\n",
       "          2.04345439e-02,   2.02308660e-02,   2.11140505e-02,\n",
       "          2.31859022e-02,   2.09675721e-02,   2.20381059e-02,\n",
       "          2.97405562e-02,   2.47070678e-02,   1.76211874e-02,\n",
       "          1.93207146e-02,   1.61007666e-02,   1.64918560e-02,\n",
       "          2.00035414e-02,   2.02208703e-02,   1.57061681e-02,\n",
       "          1.87080961e-02,   1.33076836e-02,   1.05894659e-02,\n",
       "          1.06369380e-02,   7.36561349e-03,   5.66373854e-03,\n",
       "          1.47331012e-02,   1.20391734e-03,   5.15766534e-03,\n",
       "          4.06122696e-03,   5.04340788e-03,   1.53257831e-03,\n",
       "          6.82972894e-03,   0.00000000e+00,   2.60925029e-03,\n",
       "          1.70343315e-03,   4.09497282e-03,   8.80902104e-03,\n",
       "          9.22294822e-03,   2.65069778e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.05014293e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.54624007e-04,   8.54345419e-04,   0.00000000e+00,\n",
       "          3.41462315e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.64741130e-03]),\n",
       " array([  0.00000000e+00,   2.15688886e-03,   2.44230070e-04,\n",
       "          4.17609361e-03,   1.82173363e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.97487661e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.97518447e-03,\n",
       "          5.52556726e-04,   3.00700971e-03,   9.58448124e-04,\n",
       "          0.00000000e+00,   2.84874609e-03,   0.00000000e+00,\n",
       "          1.02008917e-02,   7.30615598e-03,   1.18377922e-02,\n",
       "          8.77533990e-03,   1.33269105e-02,   8.02634068e-03,\n",
       "          3.79993805e-03,   6.74631575e-03,   9.90284544e-03,\n",
       "          1.73943976e-02,   1.09402652e-02,   1.47657532e-02,\n",
       "          1.59227046e-02,   1.18336400e-02,   1.30281926e-02,\n",
       "          1.56088630e-02,   1.04380119e-02,   1.51050803e-02,\n",
       "          1.86777847e-02,   2.01226682e-02,   1.78747772e-02,\n",
       "          2.26748735e-02,   2.26855525e-02,   2.32530474e-02,\n",
       "          2.28949323e-02,   2.40244830e-02,   2.11152438e-02,\n",
       "          1.88944489e-02,   2.72493896e-02,   1.53788378e-02,\n",
       "          2.06826765e-02,   2.06833756e-02,   2.18547768e-02,\n",
       "          2.04992081e-02,   1.96014769e-02,   2.11940174e-02,\n",
       "          2.30628736e-02,   2.10772616e-02,   2.19285202e-02,\n",
       "          2.95151893e-02,   2.47546852e-02,   1.72734788e-02,\n",
       "          1.92327438e-02,   1.60939923e-02,   1.66826711e-02,\n",
       "          1.99911550e-02,   2.04420097e-02,   1.56546233e-02,\n",
       "          1.85379779e-02,   1.34606135e-02,   1.04958373e-02,\n",
       "          1.06264699e-02,   7.34237835e-03,   5.62874306e-03,\n",
       "          1.48553692e-02,   9.27682780e-04,   5.21180253e-03,\n",
       "          4.05839199e-03,   4.55906926e-03,   1.54616439e-03,\n",
       "          6.83071595e-03,   0.00000000e+00,   2.77390944e-03,\n",
       "          1.74325187e-03,   4.40937408e-03,   8.87452552e-03,\n",
       "          9.35432332e-03,   2.80296987e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.04821803e-04,\n",
       "          7.00158636e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.32040882e-04,   5.92831186e-04,   0.00000000e+00,\n",
       "          3.15518367e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.65391305e-03]),\n",
       " array([  0.00000000e+00,   1.90757897e-03,   5.14352777e-04,\n",
       "          4.18607787e-03,   1.48563598e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.83915577e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.77532014e-03,\n",
       "          9.83471872e-04,   2.69970945e-03,   1.28125843e-03,\n",
       "          1.30785092e-04,   2.81455372e-03,   4.57817997e-05,\n",
       "          1.01714602e-02,   7.22121214e-03,   1.15476679e-02,\n",
       "          8.62800628e-03,   1.32355830e-02,   8.05714071e-03,\n",
       "          3.76765162e-03,   6.77169465e-03,   9.77179891e-03,\n",
       "          1.72830644e-02,   1.10696501e-02,   1.47684518e-02,\n",
       "          1.60497012e-02,   1.19522966e-02,   1.32241309e-02,\n",
       "          1.53404773e-02,   1.05156885e-02,   1.49218116e-02,\n",
       "          1.88331303e-02,   2.00222300e-02,   1.78627671e-02,\n",
       "          2.21747229e-02,   2.29835207e-02,   2.31725181e-02,\n",
       "          2.30656772e-02,   2.36260194e-02,   2.08562738e-02,\n",
       "          1.87380567e-02,   2.73746971e-02,   1.53936009e-02,\n",
       "          2.08454026e-02,   2.08888239e-02,   2.18987586e-02,\n",
       "          2.05690812e-02,   2.02735855e-02,   2.10846057e-02,\n",
       "          2.32497747e-02,   2.10087253e-02,   2.20852375e-02,\n",
       "          2.98316504e-02,   2.46620050e-02,   1.74890407e-02,\n",
       "          1.92877771e-02,   1.61414475e-02,   1.65989100e-02,\n",
       "          1.99748624e-02,   2.02065998e-02,   1.57254538e-02,\n",
       "          1.86526937e-02,   1.32753003e-02,   1.05730519e-02,\n",
       "          1.07498146e-02,   7.25309017e-03,   5.61434354e-03,\n",
       "          1.46516394e-02,   1.23060688e-03,   5.16990813e-03,\n",
       "          3.92465813e-03,   4.86253847e-03,   1.59692613e-03,\n",
       "          6.58595961e-03,   0.00000000e+00,   2.71710540e-03,\n",
       "          1.68127342e-03,   4.08368021e-03,   8.81096140e-03,\n",
       "          9.35440155e-03,   2.66051783e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.99518967e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.78718348e-04,   8.44769035e-04,   0.00000000e+00,\n",
       "          3.30020271e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.76403348e-03])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F, ps = f_regression(X_good, y_good)\n",
    "# ps_corrected = multipletests(ps, method='bonferroni')\n",
    "# ps_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F.sort()\n",
    "# F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
