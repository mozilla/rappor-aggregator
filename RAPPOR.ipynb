{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RAPPOR – Server-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling scientific notation makes it a bit easier to compare numeric values with the ones logged in the R part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data files\n",
    "\n",
    "In production, the content of these files is coming from the clients. For testing, we just use files that are generated by Google's simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = \"../rappor/\"\n",
    "base += \"_tmp/python/r-gauss-small-sim_bloom_filter1_1/\"\n",
    "\n",
    "PARAMS_PATH = base + \"case_params.csv\"\n",
    "COUNTS_PATH = base + \"1/case_counts.csv\"\n",
    "MAP_PATH = base + \"case_map.csv\"\n",
    "CANDIDATES_PATH = base + \"case_unique_values.txt\" #\"case_candidates.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k, h, m, p, q, f = pd.read_csv(PARAMS_PATH).iloc[0]\n",
    "k = int(k)\n",
    "h = int(h)\n",
    "m = int(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The Bloom filter has k=4 bits and uses h=2 hash functions\n",
      "- There are m=32 cohorts\n",
      "- There is a f=0.00 probability of randomly changing a bit for the PRR\n",
      "- There is a p=0.50 (q=0.75) probability of setting a bit in the IRR to 1 if that bit was 0 in the PRR\n"
     ]
    }
   ],
   "source": [
    "print \"- The Bloom filter has k=%d bits and uses h=%d hash functions\" % (k, h)\n",
    "print \"- There are m=%d cohorts\" % m\n",
    "print \"- There is a f=%.2f probability of randomly changing a bit for the PRR\" % f\n",
    "print \"- There is a p=%.2f (q=%.2f) probability of setting a bit in the IRR to 1 if that bit was 0 in the PRR\" % (p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts\n",
    "\n",
    "Each row contains information about one cohort. The very first value in a row specifies the total number of reports in that cohort. The other values specify how often the respective bit was set in the sent Bloom Filter. Because some bits were randomly changed, the first value can be smaller or greater than the sum of the other values in that row.\n",
    "\n",
    "Cohorts without any reports are directly removed.\n",
    "\n",
    "In the real server implementation, we will need a little bit of additional logic for calculating these sums. Here, we just use what Google's implementation already provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31250</td>\n",
       "      <td>18176</td>\n",
       "      <td>19389</td>\n",
       "      <td>18710</td>\n",
       "      <td>19497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31250</td>\n",
       "      <td>18527</td>\n",
       "      <td>19047</td>\n",
       "      <td>19137</td>\n",
       "      <td>18602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31250</td>\n",
       "      <td>18500</td>\n",
       "      <td>18459</td>\n",
       "      <td>19104</td>\n",
       "      <td>19343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31250</td>\n",
       "      <td>17751</td>\n",
       "      <td>19476</td>\n",
       "      <td>18634</td>\n",
       "      <td>19038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31250</td>\n",
       "      <td>18890</td>\n",
       "      <td>19827</td>\n",
       "      <td>19512</td>\n",
       "      <td>18683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4\n",
       "0  31250  18176  19389  18710  19497\n",
       "1  31250  18527  19047  19137  18602\n",
       "2  31250  18500  18459  19104  19343\n",
       "3  31250  17751  19476  18634  19038\n",
       "4  31250  18890  19827  19512  18683"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = DataFrame.from_csv(COUNTS_PATH, header=None, index_col=None)\n",
    "counts = counts[counts[0] != 0]\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map (hash values)\n",
    "\n",
    "One row for every candidate string. The leftmost value in a row (Pandas' index) shows the respective string, the other values (number of cohorts * number of hash functions) show the hashed values of that string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>109</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>123</td>\n",
       "      <td>121</td>\n",
       "      <td>127</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>120</td>\n",
       "      <td>117</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>128</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>109</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>120</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>120</td>\n",
       "      <td>118</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2   3   4   5   6   7   8   9   10 ...    55   56   57   58   59   60  \\\n",
       "0                                          ...                                  \n",
       "v1   2   4   6   7  12   9  15  15  20  17 ...   112  109  114  115  119  120   \n",
       "v2   3   4   8   7   9  10  16  16  20  18 ...   110  110  113  114  120  117   \n",
       "v3   2   1   6   5  10  12  16  16  19  19 ...   110  109  113  115  120  119   \n",
       "v4   2   1   8   6  10  11  14  14  20  19 ...   112  110  114  113  120  117   \n",
       "v5   1   3   5   7  12  11  16  13  19  19 ...   112  111  116  114  120  118   \n",
       "\n",
       "     61   62   63   64  \n",
       "0                       \n",
       "v1  123  121  127  126  \n",
       "v2  122  122  128  126  \n",
       "v3  122  123  128  127  \n",
       "v4  123  123  128  127  \n",
       "v5  121  122  126  127  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps = DataFrame.from_csv(MAP_PATH, header=None)\n",
    "maps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### candidates\n",
    "\n",
    "Here, the candidates are simply the values that were also used by the client-side code. Generally, we would like to use a superset of these values, e.g. the most popular websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_candidates():\n",
    "    with open(CANDIDATES_PATH) as f:\n",
    "        lines = f.readlines()\n",
    "        return [candidate.strip() for candidate in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = get_candidates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for testing, we can try a superset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#candidates = [\"v%d\" % i for i in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data to separate signal and noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high-level task of the server-side is to find out which candidate strings were really used by the clients. We will use statistical techniques for doing this, namely linear regression to find out which candidate strings probably influenced the final result.\n",
    "\n",
    "Another way to think about this: In Machine Learning and statistics we are often concerned with separating signal from noise. Here, the signal is given by the hashed values of candidate strings. The noise is added on purpose by clients in order to maintain privacy. On the server-side, we then try to use statistical techniques to remove the noise from the aggregated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target values $y$: Estimating true counts of the original Bloom filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we do some basic preprocessing to be able to use the same variables that are also being used by the RAPPOR paper. This makes it a bit easier to implement the math formulas given in the paper.\n",
    "\n",
    "$N$ is a vector containing the number of reports from the individual cohorts. $c$ is a matrix\n",
    "where $c_{ij}$ tells us how often bit $j$ was set in cohort $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = counts[0].as_matrix()\n",
    "c = counts.drop([0], axis=1).as_matrix().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target values $y$ will contain estimates of how often the individual bits were really set in the original bloom filter.\n",
    "\n",
    "$$\n",
    "t_{ij} = \\frac{c_{ij} - (p + 0.5fq - 0.5fp) N_j}{(1 - f) (q - p)}\n",
    "$$\n",
    "\n",
    "$Y$ is then simply a long vector that contains the rows of $t$ flattened. `estimate_bloom_counts` calculates $y$ in a vectorized way.\n",
    "\n",
    "**TODO**: Understand why this formula holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_bloom_count(c, N):\n",
    "    Y = c - ((p + 0.5 * f * q - 0.5 * f * p) * N)\n",
    "    Y /= ((1 - f) * (q - p))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = estimate_bloom_count(c, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "print Y.shape\n",
    "assert(Y.shape == (k, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not mentioned in the paper, but actually $Y$ is then also divided by $N$ to get frequencies instead of counts. We also reshape the matrix to one long vector, and call this $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (Y / N).T.reshape(k * m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design matrix $X$:  Encoding the hashed values of candidates\n",
    "\n",
    "$X$ has the shape $km \\times M$ where\n",
    "- $k$ is the number of bits in the Bloom filter\n",
    "- $m$ is the number of cohorts\n",
    "- $M$ is the number of candidate strings\n",
    "\n",
    "Each candidate string corresponds to one feature. Each feature has $h * m$ values set to $1$, all others are $0$. This makes $X$ a sparse matrix.\n",
    "\n",
    "Each data point corresponds to one bit in a cohort. A cell in that row is set to $1$ if that bit would be set by using the respective hashed candidate string.\n",
    "\n",
    "---\n",
    "\n",
    "To get the bits set in a Bloom filter, we import a function from Google's repo. This is important because we need to make sure to use the same hash function in client and server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from client.rappor import get_bloom_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives us the bits that are set when the candidate string is hashed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bloom_bits(\"test\", 4, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can finally create $X$ by creating the matrices of the individual cohorts, and then stacking them vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = []\n",
    "\n",
    "for cohort in range(m):\n",
    "    rows = []\n",
    "    \n",
    "    for candidate in candidates:\n",
    "        bits = np.zeros(k)\n",
    "        bits_set = get_bloom_bits(candidate, cohort, h, k)\n",
    "        bits[bits_set] = 1\n",
    "        rows.append(bits)\n",
    "        \n",
    "    for row in np.array(rows).T:\n",
    "        matrix.append(row)\n",
    "\n",
    "X = np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "assert(X.shape == (k * m, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give some intuition on what we're doing here: The design matrix $X$ contains information about what bits would be set by which candidates. By using the estimated counts of the individual bits, we then try to infer which candidate strings really appeared.\n",
    "\n",
    "**TODO**: Why do we use the estimated results, instead of the observed counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso: Eliminating some candidates\n",
    "\n",
    "In the RAPPOR paper, Google says they fit a Lasso model and only continue working with candidate strings that have non-zero coefficients. This acts as a preliminary filter to make the next model simpler.\n",
    "\n",
    "**TODO**: Understand how exactly this helps\n",
    "\n",
    "However, actually, Google only performs this Lasso regression if the number of candidates $M$ is larger than $0.8 * m * k$, as this means the system is close to being underdetermined.\n",
    "\n",
    "**TODO**: Understand why this exact condition exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 102.4 | Lasso should be performed: False\n"
     ]
    }
   ],
   "source": [
    "cut_off = 0.8 * m * k\n",
    "perform_lasso = M > cut_off\n",
    "\n",
    "print M, cut_off, \"| Lasso should be performed:\", perform_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we can't use $y$ here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., -0.,  0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
       "        0.,  0., -0., -0., -0.,  0., -0., -0., -0.,  0.,  0.,  0.,  0.,\n",
       "       -0.,  0.,  0., -0.,  0.,  0., -0., -0.,  0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Lasso()\n",
    "clf.fit(X, y)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, $Y$ is needed. Scaling the target values to larger values probably weakens the l1 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -697.6163989 ,    32.50288328,    97.73164584,    89.30161109,\n",
       "        -597.87088767,   434.54180914,  -274.03407912,   494.26915214,\n",
       "          64.71538662,   -85.16068611,  1067.80928003,    81.23834505,\n",
       "         961.7721037 , -1176.95239038,   128.12292416,   553.72059658,\n",
       "       -1492.27389636,  -174.93693371,  1316.32598564,  -111.05768954,\n",
       "       -1256.69276477,   495.01066969, -2012.17399569,  -205.06669912,\n",
       "         857.75537765,   165.58727033,  2086.49381857,  -598.63817738,\n",
       "         878.19501855,  1196.13561444,  -385.63799166,  -625.38317933,\n",
       "        -271.4363655 ,   -34.40500996,   655.31914623,    65.41518844,\n",
       "        -684.80003242,     0.        , -1460.06366522,   -12.30323423,\n",
       "        -674.7521337 ,  -444.22584755,   -46.64186475,   138.21383743,\n",
       "        -512.19983772,  1179.21490703,  -146.93541826,    99.48241481,\n",
       "        -789.98091185,   125.61146522,   570.4103683 ,  -498.33628439,\n",
       "       -1083.1729962 ,   211.0305696 , -1006.95211441, -1637.14529993,\n",
       "         127.32512816,  -602.32085405,  1235.69119395, -1015.86039892,\n",
       "           0.61354669, -1176.4985728 ,   337.4805484 ,  -269.15851359,\n",
       "        -151.46566207,  -128.12468695, -1001.37722705,   674.30507387,\n",
       "         337.82469316,  -438.80684052,     3.44664483,  -473.77513585,\n",
       "         808.92661293,   205.35487163,  -502.5766647 ,  -558.42374824,\n",
       "         453.70589604,   485.49880433, -1232.74076334,  1013.50693133,\n",
       "        -330.17852393,    -0.        ,  -882.28142585,   703.35210407,\n",
       "       -1378.94329349,  -368.09512352,  -581.19693487,   401.09381695,\n",
       "         338.149132  ,   521.45765028,  1137.84182567,   283.27816316,\n",
       "        1114.58179899,  1652.61083027,   -83.00587048,   646.27638457,\n",
       "       -1538.6959382 ,  -570.54639653,   824.25894368,  2009.55897367])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Lasso()\n",
    "clf.fit(X, Y.reshape(128))\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Figure out if this is really the proper way to do it. What we call `good_candidates` here doesn't have that much overlap with the results when not using Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  7,  8, 10, 11, 12, 14, 15, 18, 21, 24, 25, 26, 28,\n",
       "       29, 34, 35, 43, 45, 47, 49, 50, 53, 56, 58, 60, 62, 67, 68, 70, 72,\n",
       "       73, 76, 77, 79, 83, 87, 88, 89, 90, 91, 92, 93, 95, 98, 99])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_candidates = np.where(clf.coef_ > 0)[0]\n",
    "good_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v2',\n",
       " 'v3',\n",
       " 'v4',\n",
       " 'v6',\n",
       " 'v8',\n",
       " 'v9',\n",
       " 'v11',\n",
       " 'v12',\n",
       " 'v13',\n",
       " 'v15',\n",
       " 'v16',\n",
       " 'v19',\n",
       " 'v22',\n",
       " 'v25',\n",
       " 'v26',\n",
       " 'v27',\n",
       " 'v29',\n",
       " 'v30',\n",
       " 'v35',\n",
       " 'v36',\n",
       " 'v44',\n",
       " 'v46',\n",
       " 'v48',\n",
       " 'v50',\n",
       " 'v51',\n",
       " 'v54',\n",
       " 'v57',\n",
       " 'v59',\n",
       " 'v61',\n",
       " 'v63',\n",
       " 'v68',\n",
       " 'v69',\n",
       " 'v71',\n",
       " 'v73',\n",
       " 'v74',\n",
       " 'v77',\n",
       " 'v78',\n",
       " 'v80',\n",
       " 'v84',\n",
       " 'v88',\n",
       " 'v89',\n",
       " 'v90',\n",
       " 'v91',\n",
       " 'v92',\n",
       " 'v93',\n",
       " 'v94',\n",
       " 'v96',\n",
       " 'v99',\n",
       " 'v100']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[candidates[i] for i in good_candidates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating standard deviations\n",
    "\n",
    "Because the estimated $y$ values are just expected values, it's useful to also take spread into account. We do this by calculating the standard deviations of our estimates.\n",
    "\n",
    "**TODO**: Understand how to derive this formula\n",
    "\n",
    "The formulas for this are not given in the paper, so the code below is directly adapted from the R code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _std_row(row, p01, p11, p2):\n",
    "    N = row[0]\n",
    "    v = row[1:]\n",
    "    \n",
    "    p_hats = (v - p01 * N) / (N * p2) # expectation of a true 1\n",
    "    p_hats = np.maximum(0, np.minimum(1, p_hats))\n",
    "    \n",
    "    r = p_hats * p11 + (1 - p_hats) * p01\n",
    "        \n",
    "    return N * r * (1 - r) / p2**2\n",
    "\n",
    "def calculate_variances(counts):\n",
    "    p01 = p * (1 - f / 2) + q * f / 2\n",
    "    p11 = q * (1 - f / 2) + p * f / 2\n",
    "    p2 = p11 - p01\n",
    "    \n",
    "    N = counts[0].as_matrix()\n",
    "    \n",
    "    return (np.sqrt(counts.apply(lambda row: _std_row(row, p01, p11, p2), axis=1).as_matrix().T) / N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stds = calculate_variances(counts).reshape((k * m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we will use the standard deviations to resample the estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the data matrix and target values\n",
    "\n",
    "I'm not entirely sure why this is needed, and it's not mentioned in the paper, but Google also normalizes $X$ and $y$ to new variables $A, b$.\n",
    "\n",
    "**TODO**: Understand why exactly this is needed. It seems like scaling normalization, but the $\\min$ term makes it a bit odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_normalization(stds):\n",
    "    w = 1 / stds\n",
    "    w_median = np.median(w[np.isfinite(w)])\n",
    "\n",
    "    if not np.isfinite(w_median):\n",
    "        w_median = 1\n",
    "\n",
    "    w = np.minimum(w, 2 * w_median)\n",
    "    w = w / w.mean()\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(X, y, stds):\n",
    "    w = calculate_normalization(stds)\n",
    "    \n",
    "    # Multiplying to a digonal matrix is equivalent to multiplying each\n",
    "    # row of X with the corresponding cell on the diagonal\n",
    "    diag = np.diag(w)\n",
    "    A = diag.dot(X)\n",
    "    b = diag.dot(y)\n",
    "    \n",
    "    return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A, b = normalize(X, y, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Linear Regression\n",
    "\n",
    "In the paper, Google says they perform a \"regular least-squares regression using the selected variables\" but this is not true.\n",
    "The input variables are changed a bit, as we saw before. Additionally, the linear regression [involves additional constraints](https://github.com/google/rappor/blob/master/analysis/R/alternative.R#L22-26) that are not described in the paper.\n",
    "\n",
    "The following constraints must hold for valid coefficients $x$:\n",
    "\n",
    "#### $x$ must be nonnegative\n",
    "\n",
    "The coefficients correspond to frequencies of how often the respective candidate was approximately reported by a client, so it makes sense for them to be nonnegative.\n",
    "\n",
    "A nonnegativity constraint is supported by many least squares implementations.\n",
    "\n",
    "####  $x$ sums up to a value smaller or equal to $1$\n",
    "\n",
    "$y$ contains frequencies, not counts. So it makes sense that $x$ also gives us frequencies.\n",
    "\n",
    "#### Standard deviation\n",
    "\n",
    "If we use $x$ to estimate the bit counts in the Bloom filter, this estimate may not exceed the $y$ estimates by more than 3 standard deviations. This is just a constraint to make sure that we don't end up with a solution $x$ that works super well for some estimates but not at all for others.\n",
    "\n",
    "This third constraint however makes things a bit more difficult. In general, sklearn and SciPy cannot deal with it automatically. Because of this, we have to fallback to a more low-level optimizer here that allows us to encode arbitrary constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, nnls\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third constraint, we introduce a new variable $yy$ that gives a limit for how much predicted values may differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yy = np.minimum(1, np.maximum(y + 3 * stds, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the generality of our optimizer, it's important to choose a good first guess $x_0$. We generate this guess by quickly training a model using the first two constraints, but without the third. This turns out to be the critical change that allows us to get the same results as the optimization library used in R by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0, _ = nnls(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is simply least squares, i.e. we want to minimize $||Ax - b||_2^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    return norm(A.dot(x) - b, ord=2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we encode the third constraint, and run the minimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_deviation_constraint = {\n",
    "    \"type\": \"ineq\",\n",
    "    \"fun\": lambda x: max(X.dot(x) - yy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00444591,  0.        ,  0.00010478,  0.00726803,\n",
       "        0.        ,  0.0023589 ,  0.        ,  0.00839603,  0.        ,\n",
       "        0.        ,  0.00092728,  0.00921657,  0.        ,  0.00762413,\n",
       "        0.00009158,  0.00100493,  0.00590351,  0.00408931,  0.00490503,\n",
       "        0.        ,  0.01101859,  0.00531075,  0.00509771,  0.01098121,\n",
       "        0.00919817,  0.01121164,  0.01146852,  0.00844996,  0.01057589,\n",
       "        0.00777264,  0.00881058,  0.01289039,  0.01166336,  0.01571904,\n",
       "        0.01767198,  0.01949581,  0.01953498,  0.01078894,  0.01347231,\n",
       "        0.0283534 ,  0.0192417 ,  0.0218468 ,  0.02023765,  0.02186906,\n",
       "        0.02015059,  0.02218248,  0.02409973,  0.02778523,  0.02325137,\n",
       "        0.02337359,  0.02843361,  0.02977673,  0.02370705,  0.02811039,\n",
       "        0.01884789,  0.02654317,  0.02167909,  0.01611087,  0.02293308,\n",
       "        0.02342292,  0.02259553,  0.02389227,  0.00822675,  0.01286657,\n",
       "        0.01582145,  0.00981613,  0.01075878,  0.00761649,  0.00900014,\n",
       "        0.00593015,  0.0072856 ,  0.01273058,  0.00682386,  0.00732738,\n",
       "        0.00838893,  0.00785712,  0.00623504,  0.0044913 ,  0.00141231,\n",
       "        0.00231317,  0.00492569,  0.00056996,  0.00128195,  0.00644886,\n",
       "        0.00208228,  0.        ,  0.00095233,  0.        ,  0.00106933,\n",
       "        0.00193883,  0.00126272,  0.00811342,  0.        ,  0.00227227,\n",
       "        0.00117194,  0.00434539,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = minimize(cost,\n",
    "         x0=x0,\n",
    "         method=\"SLSQP\",\n",
    "         constraints=standard_deviation_constraint,\n",
    "         bounds=zip(np.zeros(M), np.ones(M))\n",
    "        ).x\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It depends a bit on the dataset, but usually we get the exact same results as Google's RAPPOR here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y, stds):\n",
    "    A, b = normalize(X, y, stds)\n",
    "    yy = np.minimum(1, np.maximum(y + 3 * stds, 0.01))\n",
    "    \n",
    "    standard_deviation_constraint = {\n",
    "        \"type\": \"ineq\",\n",
    "        \"fun\": lambda x, X, yy: max(X.dot(x) - yy),\n",
    "        \"args\": (X, yy)\n",
    "    }\n",
    "    \n",
    "    x0, _ = nnls(A, b)\n",
    "    x = minimize(cost,\n",
    "         x0=x0,\n",
    "         method=\"SLSQP\", # TNC or SLSQP\n",
    "         constraints=standard_deviation_constraint,\n",
    "         bounds=zip(np.zeros(M), np.ones(M)),\n",
    "         options={ \"maxiter\": 1000 }\n",
    "        ).x\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNC\n",
    "\n",
    "TNC finds the exact same optimum as R. However, this only works here because the best solution is independent of the third constraint in this case. Of course, generally that's not true, so we can't use TNC without ditching the third constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tnc_options = {\n",
    "    \"maxiter\": 100000000,\n",
    "    \"disp\": True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00445729,  0.        ,  0.        ,  0.00583421,\n",
       "        0.        ,  0.00159147,  0.        ,  0.00850794,  0.        ,\n",
       "        0.        ,  0.00068112,  0.01044523,  0.        ,  0.00757138,\n",
       "        0.        ,  0.00175783,  0.00743167,  0.00358884,  0.00484413,\n",
       "        0.        ,  0.01061659,  0.00466425,  0.00652856,  0.01132806,\n",
       "        0.01000026,  0.01053259,  0.01042052,  0.00754123,  0.01139442,\n",
       "        0.00918901,  0.00784926,  0.01262708,  0.01200404,  0.01647842,\n",
       "        0.01908947,  0.01880005,  0.01935962,  0.01002251,  0.0135377 ,\n",
       "        0.02750956,  0.01929309,  0.02159292,  0.01973754,  0.02143627,\n",
       "        0.02142623,  0.0218979 ,  0.02445541,  0.0271694 ,  0.0230246 ,\n",
       "        0.02337885,  0.02798415,  0.02893956,  0.02364532,  0.02852314,\n",
       "        0.01999058,  0.02637652,  0.02168017,  0.01770654,  0.02252696,\n",
       "        0.02228578,  0.02173312,  0.02422969,  0.00706448,  0.01350732,\n",
       "        0.01512387,  0.0097254 ,  0.01113905,  0.00832427,  0.00892384,\n",
       "        0.00652871,  0.0065614 ,  0.01281561,  0.00752645,  0.00658245,\n",
       "        0.00817016,  0.00829095,  0.00686789,  0.00403345,  0.00273115,\n",
       "        0.00205727,  0.0043694 ,  0.00098646,  0.00114034,  0.00569922,\n",
       "        0.00246119,  0.        ,  0.00118121,  0.        ,  0.00148277,\n",
       "        0.00143475,  0.00177298,  0.00809766,  0.        ,  0.0026095 ,\n",
       "        0.00071872,  0.00298755,  0.        ,  0.00058444,  0.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(cost,\n",
    "         x0=x0,\n",
    "         method=\"TNC\",\n",
    "         bounds=zip(np.zeros(M), np.ones(M)),\n",
    "         options=tnc_options\n",
    "        ).x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "A popular way to get more data is resampling. Here, we use the standard deviations to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import normal, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resample(y, stds):\n",
    "    y_old = y\n",
    "    \n",
    "    deviation = np.array([normal(0, std) for std in stds])\n",
    "    y = y + deviation\n",
    "    \n",
    "    print sum(y_old - y)\n",
    "    \n",
    "    stds = stds * np.sqrt(2)\n",
    "        \n",
    "    return y, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.171488472348\n",
      "-0.157453112945\n",
      "-0.00479472924269\n",
      "-0.151043402239\n"
     ]
    }
   ],
   "source": [
    "coefs = []\n",
    "\n",
    "for i in range(5):\n",
    "    if i > 0:\n",
    "        y_resampled, stds_resampled = resample(y, stds)\n",
    "    else:\n",
    "        y_resampled, stds_resampled = y, stds\n",
    "        \n",
    "    coefs.append(fit(X, y_resampled, stds_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.        ,  0.00444591,  0.        ,  0.00010478,  0.00726803,\n",
       "         0.        ,  0.0023589 ,  0.        ,  0.00839603,  0.        ,\n",
       "         0.        ,  0.00092728,  0.00921657,  0.        ,  0.00762413,\n",
       "         0.00009158,  0.00100493,  0.00590351,  0.00408931,  0.00490503,\n",
       "         0.        ,  0.01101859,  0.00531075,  0.00509771,  0.01098121,\n",
       "         0.00919817,  0.01121164,  0.01146852,  0.00844996,  0.01057589,\n",
       "         0.00777264,  0.00881058,  0.01289039,  0.01166336,  0.01571904,\n",
       "         0.01767198,  0.01949581,  0.01953498,  0.01078894,  0.01347231,\n",
       "         0.0283534 ,  0.0192417 ,  0.0218468 ,  0.02023765,  0.02186906,\n",
       "         0.02015059,  0.02218248,  0.02409973,  0.02778523,  0.02325137,\n",
       "         0.02337359,  0.02843361,  0.02977673,  0.02370705,  0.02811039,\n",
       "         0.01884789,  0.02654317,  0.02167909,  0.01611087,  0.02293308,\n",
       "         0.02342292,  0.02259553,  0.02389227,  0.00822675,  0.01286657,\n",
       "         0.01582145,  0.00981613,  0.01075878,  0.00761649,  0.00900014,\n",
       "         0.00593015,  0.0072856 ,  0.01273058,  0.00682386,  0.00732738,\n",
       "         0.00838893,  0.00785712,  0.00623504,  0.0044913 ,  0.00141231,\n",
       "         0.00231317,  0.00492569,  0.00056996,  0.00128195,  0.00644886,\n",
       "         0.00208228,  0.        ,  0.00095233,  0.        ,  0.00106933,\n",
       "         0.00193883,  0.00126272,  0.00811342,  0.        ,  0.00227227,\n",
       "         0.00117194,  0.00434539,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 0.        ,  0.00566023,  0.        ,  0.        ,  0.00688756,\n",
       "         0.        ,  0.00201768,  0.        ,  0.00823667,  0.        ,\n",
       "         0.        ,  0.00154124,  0.01001595,  0.        ,  0.00690768,\n",
       "         0.        ,  0.00268301,  0.00669932,  0.00311149,  0.00401072,\n",
       "         0.        ,  0.01004347,  0.00551808,  0.00578469,  0.01119222,\n",
       "         0.01009452,  0.01054793,  0.01106318,  0.00747831,  0.01116577,\n",
       "         0.00979535,  0.0073845 ,  0.01255799,  0.01142399,  0.01735768,\n",
       "         0.01835857,  0.01854999,  0.01916863,  0.01111542,  0.01339837,\n",
       "         0.02766276,  0.01949295,  0.02137146,  0.01915412,  0.02141427,\n",
       "         0.02168047,  0.02121253,  0.02410168,  0.0268277 ,  0.02347557,\n",
       "         0.0237742 ,  0.02732295,  0.0280831 ,  0.0236855 ,  0.02866359,\n",
       "         0.01980655,  0.02670767,  0.02266023,  0.01822925,  0.02294661,\n",
       "         0.02177497,  0.02152836,  0.02363134,  0.00784259,  0.01261511,\n",
       "         0.01609454,  0.0092125 ,  0.01047709,  0.00891487,  0.00871593,\n",
       "         0.00664424,  0.00666537,  0.01327362,  0.00666524,  0.00792454,\n",
       "         0.00835162,  0.00759098,  0.00530524,  0.00521848,  0.00296316,\n",
       "         0.00166025,  0.00345977,  0.00195788,  0.00059575,  0.00615752,\n",
       "         0.00179392,  0.        ,  0.00119529,  0.00026368,  0.00185764,\n",
       "         0.00181158,  0.00139458,  0.00833479,  0.        ,  0.00250192,\n",
       "         0.00131806,  0.00361761,  0.        ,  0.00012084,  0.        ]),\n",
       " array([ 0.        ,  0.00444095,  0.        ,  0.00010371,  0.0072798 ,\n",
       "         0.00000075,  0.00235609,  0.        ,  0.00839224,  0.        ,\n",
       "         0.        ,  0.00092129,  0.0092075 ,  0.        ,  0.0076351 ,\n",
       "         0.00009494,  0.00099467,  0.00588753,  0.00409654,  0.00490895,\n",
       "         0.00000025,  0.01102899,  0.00532113,  0.00509687,  0.01096825,\n",
       "         0.00919263,  0.01121786,  0.01147915,  0.00846716,  0.01056871,\n",
       "         0.00775297,  0.00882336,  0.01288629,  0.01166674,  0.01571427,\n",
       "         0.01766129,  0.01950726,  0.01952522,  0.0108003 ,  0.01345805,\n",
       "         0.02836437,  0.01923013,  0.0218544 ,  0.02024973,  0.02187355,\n",
       "         0.02014094,  0.02218845,  0.02409509,  0.02779192,  0.0232459 ,\n",
       "         0.02337315,  0.02844069,  0.02978287,  0.02371838,  0.02810199,\n",
       "         0.01883291,  0.0265346 ,  0.02167452,  0.01609676,  0.02293676,\n",
       "         0.02344125,  0.02261161,  0.02389437,  0.00824112,  0.01285852,\n",
       "         0.01582705,  0.00982174,  0.01075487,  0.0076193 ,  0.00899186,\n",
       "         0.0059093 ,  0.00729967,  0.01271551,  0.00682557,  0.0073412 ,\n",
       "         0.00838403,  0.00784898,  0.00623884,  0.00449352,  0.00141029,\n",
       "         0.00231794,  0.0049273 ,  0.00055462,  0.00127658,  0.00645708,\n",
       "         0.00208607,  0.        ,  0.00095333,  0.00000028,  0.00106179,\n",
       "         0.00195013,  0.00126597,  0.0081111 ,  0.        ,  0.00226763,\n",
       "         0.00116856,  0.00434592,  0.00000015,  0.00000046,  0.00000024]),\n",
       " array([ 0.        ,  0.00446797,  0.        ,  0.        ,  0.00555223,\n",
       "         0.        ,  0.00143404,  0.        ,  0.008451  ,  0.        ,\n",
       "         0.        ,  0.00078744,  0.01050422,  0.        ,  0.00719575,\n",
       "         0.        ,  0.00199707,  0.00791728,  0.00332594,  0.00506832,\n",
       "         0.        ,  0.01069135,  0.00422703,  0.00621893,  0.01190873,\n",
       "         0.01022614,  0.01060224,  0.00964215,  0.00755764,  0.0116392 ,\n",
       "         0.00970092,  0.00735635,  0.01229023,  0.01230489,  0.01704548,\n",
       "         0.01919951,  0.01865571,  0.01990403,  0.00948301,  0.01374324,\n",
       "         0.02717592,  0.01901767,  0.02121426,  0.02024494,  0.02158047,\n",
       "         0.02170845,  0.02175724,  0.02460511,  0.02683809,  0.02341835,\n",
       "         0.02386153,  0.02826608,  0.0282269 ,  0.02376805,  0.02811761,\n",
       "         0.01948744,  0.02621363,  0.02111315,  0.01807104,  0.02268211,\n",
       "         0.02206706,  0.02171325,  0.02467791,  0.00661013,  0.01378152,\n",
       "         0.01516644,  0.00935595,  0.01109068,  0.00795412,  0.00865076,\n",
       "         0.00712449,  0.00624649,  0.01324375,  0.00796184,  0.0062664 ,\n",
       "         0.00831315,  0.00789236,  0.00731022,  0.00425949,  0.00256472,\n",
       "         0.00180749,  0.0045025 ,  0.00136949,  0.00087518,  0.00513677,\n",
       "         0.00281095,  0.        ,  0.00139888,  0.        ,  0.001534  ,\n",
       "         0.00180463,  0.00158331,  0.00821055,  0.        ,  0.00275687,\n",
       "         0.00099229,  0.00305321,  0.        ,  0.00043563,  0.        ]),\n",
       " array([ 0.        ,  0.00377879,  0.        ,  0.        ,  0.00703725,\n",
       "         0.        ,  0.00149595,  0.        ,  0.00985286,  0.        ,\n",
       "         0.        ,  0.00074263,  0.00991503,  0.        ,  0.00766616,\n",
       "         0.        ,  0.00274341,  0.00718939,  0.0023246 ,  0.00555228,\n",
       "         0.        ,  0.00909344,  0.0054444 ,  0.00535608,  0.01144101,\n",
       "         0.01067009,  0.00997   ,  0.00998157,  0.00702054,  0.01112809,\n",
       "         0.00961022,  0.00780908,  0.0126983 ,  0.01222561,  0.01690093,\n",
       "         0.01840415,  0.01843752,  0.01936611,  0.00964292,  0.01430543,\n",
       "         0.0292723 ,  0.02035683,  0.022214  ,  0.01949757,  0.02122498,\n",
       "         0.02016831,  0.02145189,  0.02490654,  0.02854314,  0.02357989,\n",
       "         0.02298987,  0.02751273,  0.03039881,  0.02365497,  0.02900933,\n",
       "         0.02009097,  0.02596733,  0.02190378,  0.01739332,  0.02394207,\n",
       "         0.02274874,  0.02192352,  0.02436262,  0.00638695,  0.01198285,\n",
       "         0.0161085 ,  0.0096103 ,  0.01017243,  0.00839077,  0.0090655 ,\n",
       "         0.00661641,  0.00551498,  0.01309172,  0.00617578,  0.00718781,\n",
       "         0.00894682,  0.00831425,  0.0062619 ,  0.0044283 ,  0.00185255,\n",
       "         0.00193612,  0.00373915,  0.00151038,  0.00058121,  0.00629993,\n",
       "         0.00346521,  0.        ,  0.00139042,  0.        ,  0.00143252,\n",
       "         0.00119163,  0.00119233,  0.00747944,  0.        ,  0.00241281,\n",
       "         0.        ,  0.00360937,  0.        ,  0.        ,  0.        ])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The fundamental idea here is that the coefficients found by the linear regression are significant if they are stable across several resamplings.\n",
    "\n",
    "In the following, the mean and standard deviation of each coefficient is calculated. Then, coefficients with a low standard deviation (in relation to their mean) are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_total = N.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_mean = np.floor(np.mean(coefs, axis=0) * N_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_std = np.std(coefs, axis=0, ddof=1) * N_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Google's code, `cut_off_factor` is set to $2$. In our case, we might want to set it to a higher value since we have less variance because our optimizer doesn't work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut_off_factor = 2\n",
    "reported = np.where(coef_mean > (cut_off_factor * coef_std + 1e-6))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reported.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_coefs = coef_mean[reported]\n",
    "mod_stds = coef_std[reported]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can print a list of the candidates that were found and the corresponding estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    52.  29253.]\n",
      " [    54.  28400.]\n",
      " [    40.  28165.]\n",
      " [    51.  27995.]\n",
      " [    48.  27557.]\n",
      " [    56.  26393.]\n",
      " [    47.  24361.]\n",
      " [    62.  24091.]\n",
      " [    53.  23706.]\n",
      " [    50.  23474.]\n",
      " [    49.  23394.]\n",
      " [    59.  23088.]\n",
      " [    60.  22690.]\n",
      " [    61.  22074.]\n",
      " [    57.  21806.]\n",
      " [    46.  21758.]\n",
      " [    42.  21700.]\n",
      " [    44.  21592.]\n",
      " [    45.  20769.]\n",
      " [    43.  19876.]\n",
      " [    37.  19499.]\n",
      " [    41.  19467.]\n",
      " [    55.  19413.]\n",
      " [    36.  18929.]\n",
      " [    35.  18259.]\n",
      " [    58.  17180.]\n",
      " [    34.  16547.]\n",
      " [    65.  15803.]\n",
      " [    39.  13675.]\n",
      " [    72.  13011.]\n",
      " [    64.  12820.]\n",
      " [    32.  12664.]\n",
      " [    33.  11856.]\n",
      " [    24.  11298.]\n",
      " [    29.  11015.]\n",
      " [    27.  10726.]\n",
      " [    26.  10709.]\n",
      " [    67.  10650.]\n",
      " [    21.  10375.]\n",
      " [    38.  10366.]\n",
      " [    25.   9876.]\n",
      " [    12.   9771.]\n",
      " [    66.   9563.]\n",
      " [    30.   8926.]\n",
      " [    69.   8884.]\n",
      " [     8.   8665.]\n",
      " [    75.   8476.]\n",
      " [    68.   8099.]\n",
      " [    92.   8049.]\n",
      " [    31.   8036.]\n",
      " [    76.   7900.]\n",
      " [    28.   7794.]\n",
      " [    63.   7461.]\n",
      " [    14.   7405.]\n",
      " [    74.   7209.]\n",
      " [    73.   6890.]\n",
      " [     4.   6804.]\n",
      " [    17.   6719.]\n",
      " [    71.   6602.]\n",
      " [    70.   6444.]\n",
      " [    77.   6270.]\n",
      " [    84.   6100.]\n",
      " [    23.   5510.]\n",
      " [    22.   5164.]\n",
      " [    19.   4889.]\n",
      " [    78.   4578.]\n",
      " [     1.   4558.]\n",
      " [    81.   4310.]\n",
      " [    96.   3794.]\n",
      " [    18.   3389.]\n",
      " [    85.   2447.]\n",
      " [    94.   2442.]\n",
      " [    79.   2040.]\n",
      " [    80.   2006.]\n",
      " [     6.   1932.]\n",
      " [    16.   1884.]\n",
      " [    90.   1739.]\n",
      " [    89.   1391.]\n",
      " [    91.   1339.]\n",
      " [    82.   1192.]\n",
      " [    87.   1178.]\n",
      " [    11.    983.]\n",
      " [    95.    930.]\n",
      " [    83.    922.]\n",
      " [    98.    111.]\n",
      " [    88.     52.]\n",
      " [     3.     41.]\n",
      " [    15.     37.]\n",
      " [     5.      0.]\n",
      " [     2.      0.]\n",
      " [     7.      0.]\n",
      " [    99.      0.]\n",
      " [     9.      0.]\n",
      " [    10.      0.]\n",
      " [    13.      0.]\n",
      " [    20.      0.]\n",
      " [    86.      0.]\n",
      " [    93.      0.]\n",
      " [    97.      0.]\n",
      " [     0.      0.]]\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(coef_mean)[::-1]\n",
    "print np.array(zip(indices, coef_mean[indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "For a visual comparison, it's helpful to plot the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_data = DataFrame.from_csv(base + \"1/case_true_values.csv\")\n",
    "counts = dict(Counter(true_data[\"value\"]))\n",
    "original = [counts['v%d' % i] for i in range(1, 101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original = np.array(original + [0] * (M - len(original)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 100 artists>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108b2cd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(M), original, width=1., color='orange', edgecolor='darkorange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the reported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = np.zeros(M)\n",
    "total[reported] = mod_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe, we don't want to report on estimates that are very low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total[total < 6000] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 100 artists>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102e0f890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(M), original, width=1., color='orange', edgecolor='darkorange')\n",
    "plt.bar(range(M), total, width=1., edgecolor='darkblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the quality of decoding\n",
    "\n",
    "It would be nice to have an automatic way of judging how good the decoding worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error\n",
    "\n",
    "A simple such measure is the Manhattan distance between the actual and the reported distribution, divided by the number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(actual, reported):\n",
    "    return np.sum(np.abs(actual - reported)) / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484.9099999999999"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(original, coef_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is computing the count of wrong estimates (by how much we overshoot / undershoot) divided by the real counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24849099999999999"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(coef_mean - original)) / original.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "A more sophisticated way of measuring the quality is in terms of precision and recall.\n",
    "\n",
    "- Precision: Out of the candidates that the analysis found, how many were actually reported from clients? $\\mathit{tp} / (\\mathit{tp} + \\mathit{fp})$\n",
    "- Recall: Out of the actually reported candidates, how many are found by the analysis? $\\mathit{tp} / (\\mathit{tp} + \\mathit{fn})$\n",
    "\n",
    "The problem is that here it's not clear how to calculate tp, tn, fp, fn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplified\n",
    "\n",
    "In the original repo, Google ignores estimates for calculating these metrics. If a reported string is found by the analysis, it's counted as a true positive even if the estimated counts are completely off. The only thing that matters here is whether a string was reported/found or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = set([candidates[i] for i in reported])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = set(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = len(found.intersection(sent))\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = len(found - sent)\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = len(sent - found)\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tp / float(tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = tp / float(tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy\n",
    "\n",
    "It's not clear if we really want to ignore estimates. Here, each reported or actual occurence is counted as one data point.\n",
    "\n",
    "The true positive count is by how much reported and actual agree. Reported overshooting corresponds to false positives, undershooting corresponds to false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874357.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = np.minimum(coef_mean, original).sum()\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122848.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = coef_mean - original\n",
    "fp = diff[diff > 0].sum()\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125643.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = -diff[diff < 0].sum()\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summed = tp + fp + fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = tp / summed\n",
    "fp = fp / summed\n",
    "fn = fn / summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87680767745849642"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87435699999999994"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = tp / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring collisions\n",
    "\n",
    "Some collisions are to be expected because of the Bloom filter. These are just some experiments for automatically calculating this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[0, 0]': 3,\n",
       "         '[0, 1]': 6,\n",
       "         '[0, 2]': 7,\n",
       "         '[0, 3]': 5,\n",
       "         '[1, 0]': 9,\n",
       "         '[1, 1]': 6,\n",
       "         '[1, 2]': 7,\n",
       "         '[1, 3]': 6,\n",
       "         '[2, 0]': 2,\n",
       "         '[2, 1]': 6,\n",
       "         '[2, 2]': 10,\n",
       "         '[2, 3]': 9,\n",
       "         '[3, 0]': 3,\n",
       "         '[3, 1]': 6,\n",
       "         '[3, 2]': 4,\n",
       "         '[3, 3]': 11})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter([str(get_bloom_bits(\"v%d\" % i , 0, h, k)) for i in range(100)])\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "counter = defaultdict(int)\n",
    "\n",
    "for i in range(100):\n",
    "    candidate = \"v%d\" % i\n",
    "    hashed = []\n",
    "    \n",
    "    for cohort in range(m):\n",
    "        hashed += get_bloom_bits(\"v%d\" % i , cohort, h, k)\n",
    "    \n",
    "    counter[str(hashed)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Statistical Inference – Bonferroni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Google repo, they calculate some more statistical properties. However, these values are not used for further filtering, they're just saved into variables.\n",
    "\n",
    "**TODO**: We still have to figure out if we want to use techniques like these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 82)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, reported].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_inference(X, y, N, mod_coefs, mod_stds, alpha):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, $\\alpha$ is set to $0.5$; in the code it's additionally divided by the total number of reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.05 / N_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perform_inference(\n",
    "    X[:, reported],\n",
    "    y,\n",
    "    N_total,\n",
    "    mod_coefs,\n",
    "    mod_stds,\n",
    "    alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F, ps = f_regression(X_good, y_good)\n",
    "# ps_corrected = multipletests(ps, method='bonferroni')\n",
    "# ps_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F.sort()\n",
    "# F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
